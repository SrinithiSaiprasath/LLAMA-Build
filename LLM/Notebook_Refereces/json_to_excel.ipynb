{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#jsonl_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs.jsonl'\n",
    "jsonl_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\train-v2.0.json'\n",
    "\n",
    "data = []\n",
    "with open(jsonl_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#excel_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs.xlsx'\n",
    "excel_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\SQuAD.xlsx'\n",
    "csv_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\SQuAD.csv'\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "jsonl_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\train-v2.0.json'\n",
    "csv_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\SQuAD.csv'\n",
    "\n",
    "with open(jsonl_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "df = pd.json_normalize(data)\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "json_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\train-v2.0.json'\n",
    "csv_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD'\n",
    "\n",
    "# Load your JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create lists to hold the extracted data\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "# Extract data\n",
    "for article in data['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qas in paragraph['qas']:\n",
    "            question = qas['question']\n",
    "            if qas['answers']:  # Check if 'answers' list is not empty\n",
    "                answer = qas['answers'][0]['text']\n",
    "            else:\n",
    "                answer = 'No answer available'  # Handle the case where 'answers' is empty\n",
    "            contexts.append(context)\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Context': contexts,\n",
    "    'Question': questions,\n",
    "    'Answer': answers\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_file_path = os.path.join(csv_file_path, 'SQuAD.xlsx')\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4:\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "jsonl_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs.jsonl'\n",
    "csv_file_path = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs_1.csv'\n",
    "\n",
    "# Initialize an empty list to store the parsed data\n",
    "data = []\n",
    "\n",
    "# Open the .jsonl file and read line by line\n",
    "with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        # Parse each line as a JSON object\n",
    "        record = json.loads(line.strip())\n",
    "        \n",
    "        # Extract the relevant fields\n",
    "        post_number = record.get('post_number', [None])[0]\n",
    "        system_message = record.get('system_message', [None])[0]\n",
    "        conversation = record.get('conversation', [])\n",
    "        \n",
    "        # Flatten the conversation into individual messages\n",
    "        for entry in conversation:\n",
    "            user = entry.get('user', '')\n",
    "            message = entry.get('message', '')\n",
    "            data.append([post_number, system_message, user, message])\n",
    "\n",
    "# Define the header for the CSV file\n",
    "header = ['post_number', 'system_message', 'user', 'message']\n",
    "\n",
    "# Write the parsed data to a CSV file\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f'Data has been successfully written to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5:\n",
    "\n",
    "import json\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "def is_valid_url(url):\n",
    "    # Check if URL length is within the acceptable limit for Excel\n",
    "    return len(url) <= 2079\n",
    "\n",
    "def is_valid_text(text):\n",
    "    # Check if text length is within the acceptable limit for Excel\n",
    "    return len(text) <= 32767\n",
    "\n",
    "def write_to_excel(json_file, excel_file):\n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Create an Excel workbook and worksheet\n",
    "    workbook = xlsxwriter.Workbook(excel_file)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    # Define the header\n",
    "    headers = ['Field1', 'Field2', 'Field3']  # Update these as per your JSON structure\n",
    "    for col_num, header in enumerate(headers):\n",
    "        worksheet.write(0, col_num, header)\n",
    "\n",
    "    # Write data to worksheet\n",
    "    row_num = 1\n",
    "    for item in data:\n",
    "        # Extract fields from JSON item\n",
    "        field1 = item.get('field1', '')\n",
    "        field2 = item.get('field2', '')\n",
    "        field3 = item.get('field3', '')\n",
    "\n",
    "        # Validate text fields\n",
    "        field1 = field1 if is_valid_text(field1) else ''\n",
    "        field2 = field2 if is_valid_text(field2) else ''\n",
    "        field3 = field3 if is_valid_text(field3) else ''\n",
    "\n",
    "        # Write fields to the worksheet\n",
    "        worksheet.write(row_num, 0, field1)\n",
    "        worksheet.write(row_num, 1, field2)\n",
    "        worksheet.write(row_num, 2, field3)\n",
    "        \n",
    "        # Increment row number for the next entry\n",
    "        row_num += 1\n",
    "    \n",
    "    # Close the workbook\n",
    "    workbook.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs.jsonl'  # Update with your JSON file path\n",
    "    excel_file = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\ChatGPT_chatlogs_1.xlsx'  # Update with your desired Excel file path\n",
    "    write_to_excel(json_file, excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6:\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\QuaC\\train_v0.2 QuaC.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Normalize the JSON data\n",
    "normalized_data = pd.json_normalize(data['data'], \n",
    "                                    record_path=['paragraphs', 'qas'],\n",
    "                                    meta=[['paragraphs', 'context'], \n",
    "                                          ['paragraphs', 'id'],\n",
    "                                          ['paragraphs', 'section_title'],\n",
    "                                          ['paragraphs', 'background'],\n",
    "                                          ['paragraphs', 'title']],\n",
    "                                    errors='ignore')\n",
    "\n",
    "# Convert the normalized data to a DataFrame\n",
    "df = pd.DataFrame(normalized_data)\n",
    "\n",
    "df.to_excel(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\QuaC\\QuaC.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7:\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "jsonl_file = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\Q&A_Huggingface\\train.jsonl'\n",
    "excel_file = r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\Q&A_Huggingface\\Hugg_QA.xlsx'\n",
    "\n",
    "data = []\n",
    "with open(jsonl_file, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_excel(excel_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
