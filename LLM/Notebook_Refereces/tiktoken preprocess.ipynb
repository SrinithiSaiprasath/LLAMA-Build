{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [5159, 836, 374, 1556, 48406, 0]\n",
      "Decoded Text: My name is Anoop!\n"
     ]
    }
   ],
   "source": [
    "text = \"My name is Anoop!\"\n",
    "tokens = tokenizer.encode(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "decoded_text = tokenizer.decode(tokens)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = pd.read_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_12.6K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "782\n"
     ]
    }
   ],
   "source": [
    "chat_list = []\n",
    "j = 0\n",
    "for idx, row in qa_data.iterrows():\n",
    "    chat_list.append(len(tokenizer.encode(row['Question'])))\n",
    "    chat_list.append(len(tokenizer.encode(row['Answer'])))\n",
    "print(min(chat_list))\n",
    "print(max(chat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Q_Encoding_Len</th>\n",
       "      <th>A_Encoding_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you like to play a game</td>\n",
       "      <td>Sure! I'd be happy to play a game with you. Do...</td>\n",
       "      <td>[29089, 499, 1093, 311, 1514, 264, 1847]</td>\n",
       "      <td>[40914, 0, 358, 4265, 387, 6380, 311, 1514, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the other questions that I can ask them</td>\n",
       "      <td>Here are some other questions that you can ask...</td>\n",
       "      <td>[3923, 527, 279, 1023, 4860, 430, 358, 649, 26...</td>\n",
       "      <td>[8586, 527, 1063, 1023, 4860, 430, 499, 649, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is stellar abberation</td>\n",
       "      <td>Stellar aberration is the apparent change in t...</td>\n",
       "      <td>[12840, 374, 48317, 671, 655, 367]</td>\n",
       "      <td>[626, 27978, 82102, 367, 374, 279, 10186, 2349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some readings for week 6</td>\n",
       "      <td>Certainly! Here are some alternative course ti...</td>\n",
       "      <td>[3923, 527, 1063, 40174, 369, 2046, 220, 21]</td>\n",
       "      <td>[96556, 0, 5810, 527, 1063, 10778, 3388, 15671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you provide a reading list for \"The Coldes...</td>\n",
       "      <td>Certainly! Here are some suggested instruction...</td>\n",
       "      <td>[4919, 499, 3493, 264, 5403, 1160, 369, 330, 7...</td>\n",
       "      <td>[96556, 0, 5810, 527, 1063, 12090, 11470, 369,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                      Would you like to play a game   \n",
       "1   What are the other questions that I can ask them   \n",
       "2                         what is stellar abberation   \n",
       "3                  What are some readings for week 6   \n",
       "4  can you provide a reading list for \"The Coldes...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Sure! I'd be happy to play a game with you. Do...   \n",
       "1  Here are some other questions that you can ask...   \n",
       "2  Stellar aberration is the apparent change in t...   \n",
       "3  Certainly! Here are some alternative course ti...   \n",
       "4  Certainly! Here are some suggested instruction...   \n",
       "\n",
       "                                      Q_Encoding_Len  \\\n",
       "0           [29089, 499, 1093, 311, 1514, 264, 1847]   \n",
       "1  [3923, 527, 279, 1023, 4860, 430, 358, 649, 26...   \n",
       "2                 [12840, 374, 48317, 671, 655, 367]   \n",
       "3       [3923, 527, 1063, 40174, 369, 2046, 220, 21]   \n",
       "4  [4919, 499, 3493, 264, 5403, 1160, 369, 330, 7...   \n",
       "\n",
       "                                      A_Encoding_Len  \n",
       "0  [40914, 0, 358, 4265, 387, 6380, 311, 1514, 26...  \n",
       "1  [8586, 527, 1063, 1023, 4860, 430, 499, 649, 2...  \n",
       "2  [626, 27978, 82102, 367, 374, 279, 10186, 2349...  \n",
       "3  [96556, 0, 5810, 527, 1063, 10778, 3388, 15671...  \n",
       "4  [96556, 0, 5810, 527, 1063, 12090, 11470, 369,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data['Q_Encoding_Len'] = qa_data['Question'].apply(lambda x: tokenizer.encode(x))\n",
    "qa_data['A_Encoding_Len'] = qa_data['Answer'].apply(lambda x: tokenizer.encode(x))\n",
    "\n",
    "qa_data.to_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_12.6K_Tokens.csv', index=False)\n",
    "qa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you like to play a game</td>\n",
       "      <td>Sure! I'd be happy to play a game with you. Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the other questions that I can ask them</td>\n",
       "      <td>Here are some other questions that you can ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is stellar abberation</td>\n",
       "      <td>Stellar aberration is the apparent change in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some readings for week 6</td>\n",
       "      <td>Certainly! Here are some alternative course ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you provide a reading list for \"The Coldes...</td>\n",
       "      <td>Certainly! Here are some suggested instruction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                      Would you like to play a game   \n",
       "1   What are the other questions that I can ask them   \n",
       "2                         what is stellar abberation   \n",
       "3                  What are some readings for week 6   \n",
       "4  can you provide a reading list for \"The Coldes...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Sure! I'd be happy to play a game with you. Do...  \n",
       "1  Here are some other questions that you can ask...  \n",
       "2  Stellar aberration is the apparent change in t...  \n",
       "3  Certainly! Here are some alternative course ti...  \n",
       "4  Certainly! Here are some suggested instruction...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_total_encoding_length(row):\n",
    "    question_length = len(tokenizer.encode(row['Question']))\n",
    "    answer_length = len(tokenizer.encode(row['Answer']))\n",
    "    return question_length + answer_length\n",
    "\n",
    "qa_data['QA_Encoding_Len'] = qa_data.apply(get_total_encoding_length, axis=1)\n",
    "\n",
    "qa_data = qa_data[qa_data['QA_Encoding_Len']<=100]\n",
    "qa_data.drop('QA_Encoding_Len', inplace=True, axis=1)\n",
    "\n",
    "qa_data.to_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_11.9K.csv', index=False)\n",
    "qa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = pd.read_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_11.9K.csv')\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for row in qa_data.itertuples():\n",
    "    chat = row.Question + \"\\n\" + row.Answer\n",
    "    tokens = tokenizer.encode(chat)\n",
    "    padded_tokens = tokens + [0] * (100 - len(tokens)) if len(tokens) < 100 else tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 1024\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "qa_data = pd.read_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_11.9K.csv')\n",
    "\n",
    "def process_data(qa_data, tokenizer):\n",
    "    tokens = []\n",
    "    for row in qa_data.itertuples():\n",
    "        chat = row.Question + \"\\n\" + row.Answer\n",
    "        tokens.append(tokenizer.encode(chat))\n",
    "    return tokens\n",
    "\n",
    "def get_batch_tiktoken(qa_tokenized):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(batch_size):\n",
    "        rand_row = torch.randint(0, len(qa_tokenized), (1,))\n",
    "        token_len = block_size + 1\n",
    "        tokens = qa_tokenized[rand_row]\n",
    "        padded_tokens = tokens + [0] * (token_len - len(tokens)) if len(tokens) < token_len else tokens[:token_len]\n",
    "        X.append(padded_tokens[:-1])\n",
    "        Y.append(padded_tokens[1:])\n",
    "    x_batch = torch.tensor(X, dtype=torch.long)\n",
    "    y_batch = torch.tensor(Y, dtype=torch.long)\n",
    "    return x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "qa_tokenized = process_data(qa_data, tokenizer)\n",
    "batch_x, batch_y = get_batch_tiktoken(qa_tokenized)\n",
    "\n",
    "print('batch_x len: ', len(batch_x))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(f'batch_x[{i}] len: ', len(batch_x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = pd.read_csv(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\ChatGPT_chatlogs\\GPT_chatlogs_Q_Tag_11.9K.csv')\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "unique_tokens = set()\n",
    "\n",
    "for row in qa_data.itertuples():\n",
    "    chat = row.Question + \"\\n\" + row.Answer\n",
    "    tokens = tokenizer.encode(chat)\n",
    "    unique_tokens.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26467\n",
      "100235\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_tokens))\n",
    "print(max(unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM_run.py - for Char level\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Scripts')\n",
    "from LLM_Finetune_Char import Head, MultiHeadAttention, FeedFoward, Block, GPTLanguageModel, encode, decode, string_to_int, int_to_string\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = torch.load(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Models\\model-06.pth')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"Prompt (enter 'x' to exit):\\n\")\n",
    "    if prompt.lower() == \"x\":\n",
    "        break\n",
    "    context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "    generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
    "    print(f'Generated text:\\n{generated_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = pd.read_excel(r'D:\\ML_Projects\\LLM-From-Scratch-For-ChatBots-GPT2\\Data\\SQuAD\\SQuAD_Preprocessed.xlsx')\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "qa_tokens = []\n",
    "for row in qa_data.itertuples():\n",
    "    chat = \"Context: \" + row.Context + \" [SEP] Question: \" + row.Question + \" [SEP] Answer: \" + str(row.Answer)\n",
    "    tokens = tokenizer.encode(chat)\n",
    "    qa_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
